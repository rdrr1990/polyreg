---
title: "Preliminary polyreg tests"
author: "Bohdan Khomtchouk and Pete Mohanty"
date: "2/1/2018"
output: github_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, comment = "")
```

```{r}
library(partools)
library(nnet)
library(polyreg)      # version from github.com/rdrr1990/polyreg
library(ggplot2)

set.seed(2018)

getPE <- function(){
  data(prgeng)
  pe <- prgeng[,c(1,3,7:9)]
  # dummies for MS, PhD
  pe$ms <- as.integer(pe$educ == 14)
  pe$phd <- as.integer(pe$educ == 16)
  pe$educ <- NULL
  pe <<- pe
}
getPE() # code from partools, possibly only on git version
plot(density(pe$wageinc), main = "wages")
plot(density(log10(pe$wageinc+1)), main = "wages (log10 scale)")
col_stat <- function(X, fx){
  round(apply(X, 2, fx), 2)
}
col_stat(pe, mean)
col_stat(pe, sd)
col_stat(pe, range)

mse <- function(y, yhat){
  mean((y - yhat)^2)
}

loss <- matrix(nrow = 2, ncol = 4)
rownames(loss) <- c("Mean Abs Error", "Mean Squared Error")
colnames(loss) <- c("nnet", "lm", "plm2", "pl3")

pe1 <- scale(pe)
sdy <- attr(pe1,'scaled:scale')[3]
muy <- attr(pe1,'scaled:center')[3]
pe1 <- as.data.frame(pe1)
trnidxs <- sample(1:nrow(pe1),10000)
trn <- pe1[trnidxs,]
tst <- pe1[-trnidxs,]
nnout <- nnet(wageinc ~ .,trn,size=8,linout=T)
nnpred <- predict(nnout,tst)[,1]
nnpred <- nnpred * sdy + muy
yorigtst <- pe$wageinc[-trnidxs]
loss[1, 1] <- mean(abs(nnpred-yorigtst))
loss[2, 1] <- mse(nnpred, yorigtst)

lmout <- lm(wageinc ~ .,data=pe[trnidxs,])
lmpred <- predict(lmout,pe[-trnidxs,])
loss[1, 2] <- mean(abs(lmpred-yorigtst))
loss[2, 2] <- mse(lmpred, yorigtst)

# srci('~/Research/PolyReg/polyreg/plm.R')
pe2 <- pe[,c(1,2,4:6,3)]
pe2.2 <- plm(pe2,2)
nms2.2 <- c(paste('a',1:17,sep=''),'wageinc')
names(pe2.2) <- nms2.2
lmout <- lm(wageinc ~ .,data=pe2.2[trnidxs,])
lmpred <- predict(lmout,pe2.2[-trnidxs,])
loss[1,3] <- mean(abs(lmpred-yorigtst))
loss[2,3] <- mse(lmpred, yorigtst)

pe2.3 <- plm(pe2,3)
nms2.3 <- c(paste('a',1:37,sep=''),'wageinc')
names(pe2.3) <- nms2.3
lmout <- lm(wageinc ~ .,data=pe2.3[trnidxs,])
lmpred <- predict(lmout,pe2.3[-trnidxs,])
loss[1,4] <- mean(abs(lmpred-yorigtst))
loss[2, 4] <- mse(lmpred, yorigtst)

loss
log10(loss)
```

Here's a simple `keras` example (with code lightly adapted from `kerasformula`).

```{r}
library(keras)

# run install_keras() the first time

pe_copy <- pe
pe_copy$sex <- pe_copy$sex - 1
pe_copy$age <- log10(pe$age) # now appears roughly normal mean 1.6
pe_copy$wkswrkd <- pe$wkswrkd/52
pe_copy$wageinc_z <- scale(pe$wageinc) 

# dropping intercept is important
# otherwise in this case x_tmp is just pe_copy without wageinc 
x_tmp <- model.matrix(wageinc ~ -1 + age + sex + wkswrkd + ms + phd, data = pe_copy, row.names = FALSE)
P <- ncol(x_tmp)
N <- nrow(x_tmp)
# x_tmp <- scale(x_tmp)

x_train <- x_tmp[trnidxs, ]
x_test <- x_tmp[-trnidxs, ]

z_train <- pe_copy$wageinc_z[trnidxs]
z_test <- pe_copy$wageinc_z[-trnidxs]

keras_model_seq <- keras_model_sequential()
keras_model_seq %>% layer_dense(units = c(P), input_shape = c(P)) %>%
  layer_activation("linear") %>% layer_dense(1)

keras_model_seq %>% compile(
  loss = loss_mean_squared_error,
  optimizer = optimizer_adam(),
  metrics = c("mean_absolute_error", "mean_squared_error")
)

history_mse <- keras_model_seq %>% fit(x_train, z_train,
                                   epochs = 25, 
                                   batch_size = 32,
                                   validation_split = 0.2)

plot(history_mse) + theme_minimal() + ggtitle("optimizer: adam")

score <- evaluate(keras_model_seq, x_test, z_test)

loss <- cbind(loss, c(score$mean_absolute_error*sd(pe$wageinc[trnidxs]), score$mean_squared_error*var(pe$wageinc[trnidxs])))
colnames(loss)[5] <- "keras_adam"
```
Now for sgd as the optimizer...
```{r}
keras_model_seq <- keras_model_sequential()
keras_model_seq %>% layer_dense(units = c(P), input_shape = c(P)) %>%
  layer_activation("linear") %>% layer_dense(1)

keras_model_seq %>% compile(
  loss = loss_mean_squared_error,
  optimizer = optimizer_sgd(),
  metrics = c("mean_absolute_error", "mean_squared_error")
)

history_mse <- keras_model_seq %>% fit(x_train, z_train,
                                   epochs = 25,
                                   batch_size = 32,
                                   validation_split = 0.2)

plot(history_mse) + theme_minimal() + ggtitle("optimizer: stochastic gradient descent")

score <- evaluate(keras_model_seq, x_test, z_test)

loss <- cbind(loss, c(score$mean_absolute_error*sd(pe$wageinc[trnidxs]), score$mean_squared_error*var(pe$wageinc[trnidxs])))
colnames(loss)[6] <- "keras_sgd"

round(loss, 0)

# MSE and mean absolute error the same in same order?
cor(loss[1,], loss[2,], method = "spearman")




```
